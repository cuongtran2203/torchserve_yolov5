2023-04-02T08:21:52,330 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T08:21:52,330 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T08:21:53,511 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T08:21:53,511 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T08:21:53,719 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T08:21:53,719 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T08:21:53,733 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: VehicleDetection.mar
2023-04-02T08:21:53,733 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: VehicleDetection.mar
2023-04-02T08:21:55,725 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T08:21:55,725 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T08:21:55,726 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T08:21:55,726 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T08:21:55,726 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T08:21:55,726 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T08:21:55,727 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T08:21:55,727 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T08:21:55,743 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T08:21:55,743 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T08:21:55,747 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T08:21:55,747 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T08:21:55,843 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T08:21:55,843 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T08:21:55,844 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T08:21:55,844 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T08:21:55,846 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T08:21:55,846 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T08:21:55,847 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T08:21:55,847 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T08:21:55,849 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T08:21:55,849 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T08:21:56,331 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-02T08:21:56,331 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-02T08:21:56,373 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-02T08:21:56,380 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Successfully loaded /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-04-02T08:21:56,381 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - [PID]6242
2023-04-02T08:21:56,382 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Torch worker started.
2023-04-02T08:21:56,383 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T08:21:56,383 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T08:21:56,383 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Python runtime: 3.8.16
2023-04-02T08:21:56,395 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T08:21:56,395 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T08:21:56,413 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-02T08:21:56,419 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680398516419
2023-04-02T08:21:56,419 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680398516419
2023-04-02T08:21:56,507 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - model_name: VehicleDetection, batchSize: 40
2023-04-02T08:21:57,046 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 538
2023-04-02T08:21:57,046 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 538
2023-04-02T08:21:57,046 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T08:21:57,046 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T08:21:57,047 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - W-9000-VehicleDetection_1.0.ms:1309|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398517
2023-04-02T08:21:57,048 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:91|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398517
2023-04-02T08:21:57,642 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398517
2023-04-02T08:21:57,662 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:214.16204071044922|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398517
2023-04-02T08:21:57,663 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:24.00482177734375|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398517
2023-04-02T08:21:57,663 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:10.1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398517
2023-04-02T08:21:57,665 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398517
2023-04-02T08:21:57,666 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398517
2023-04-02T08:21:57,667 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398517
2023-04-02T08:21:57,668 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:11106.90234375|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398517
2023-04-02T08:21:57,674 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1233.66015625|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398517
2023-04-02T08:21:57,675 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:12.3|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398517
2023-04-02T08:22:58,012 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398578
2023-04-02T08:22:58,013 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:214.16199111938477|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398578
2023-04-02T08:22:58,014 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:24.004871368408203|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398578
2023-04-02T08:22:58,014 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:10.1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398578
2023-04-02T08:22:58,015 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398578
2023-04-02T08:22:58,016 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398578
2023-04-02T08:22:58,016 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398578
2023-04-02T08:22:58,017 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:11120.63671875|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398578
2023-04-02T08:22:58,018 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1219.94921875|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398578
2023-04-02T08:22:58,019 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:12.1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398578
2023-04-02T08:23:28,050 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680398608050
2023-04-02T08:23:28,050 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680398608050
2023-04-02T08:23:28,052 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Backend received inference at: 1680398608
2023-04-02T08:23:28,089 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Invoking custom service failed.
2023-04-02T08:23:28,090 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 38
2023-04-02T08:23:28,090 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-02T08:23:28,090 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 38
2023-04-02T08:23:28,091 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/service.py", line 120, in predict
2023-04-02T08:23:28,092 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2023-04-02T08:23:28,093 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 330, in handle
2023-04-02T08:23:28,093 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2023-04-02T08:23:28,094 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/tmp/models/6dd3ece0641d4ff6832c34736435b274/myhandler.py", line 47, in preprocess
2023-04-02T08:23:28,094 [INFO ] W-9000-VehicleDetection_1.0 ACCESS_LOG - /127.0.0.1:60368 "POST /predictions/VehicleDetection HTTP/1.1" 503 559
2023-04-02T08:23:28,095 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     im = letterbox(img, 640, stride=32, auto=True)[0]
2023-04-02T08:23:28,095 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398607
2023-04-02T08:23:28,095 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/tmp/models/6dd3ece0641d4ff6832c34736435b274/process.py", line 225, in letterbox
2023-04-02T08:23:28,096 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500436100, Inference time ns: 546759800
2023-04-02T08:23:28,096 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500436100, Inference time ns: 546759800
2023-04-02T08:23:28,096 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)
2023-04-02T08:23:28,097 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398608
2023-04-02T08:23:28,098 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - NameError: name 'cv2' is not defined
2023-04-02T08:23:58,022 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398638
2023-04-02T08:23:58,023 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:214.16199111938477|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398638
2023-04-02T08:23:58,023 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:24.004871368408203|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398638
2023-04-02T08:23:58,024 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:10.1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398638
2023-04-02T08:23:58,025 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398638
2023-04-02T08:23:58,026 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398638
2023-04-02T08:23:58,027 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398638
2023-04-02T08:23:58,028 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:11105.5078125|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398638
2023-04-02T08:23:58,029 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1235.265625|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398638
2023-04-02T08:23:58,029 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:12.3|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398638
2023-04-02T08:25:08,388 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T08:25:08,388 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T08:25:09,572 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T08:25:09,572 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T08:25:09,787 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: logs/config/20230402082402334-shutdown.cfg
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T08:25:09,787 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: logs/config/20230402082402334-shutdown.cfg
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T08:25:09,805 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20230402082402334-shutdown.cfg",
  "modelCount": 1,
  "created": 1680398642335,
  "models": {
    "VehicleDetection": {
      "1.0": {
        "defaultVersion": true,
        "marName": "VehicleDetection.mar",
        "minWorkers": 1,
        "maxWorkers": 8,
        "batchSize": 40,
        "maxBatchDelay": 500,
        "responseTimeout": 50
      }
    }
  }
}
2023-04-02T08:25:09,805 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20230402082402334-shutdown.cfg",
  "modelCount": 1,
  "created": 1680398642335,
  "models": {
    "VehicleDetection": {
      "1.0": {
        "defaultVersion": true,
        "marName": "VehicleDetection.mar",
        "minWorkers": 1,
        "maxWorkers": 8,
        "batchSize": 40,
        "maxBatchDelay": 500,
        "responseTimeout": 50
      }
    }
  }
}
2023-04-02T08:25:09,816 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20230402082402334-shutdown.cfg
2023-04-02T08:25:09,816 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20230402082402334-shutdown.cfg
2023-04-02T08:25:09,820 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20230402082402334-shutdown.cfg validated successfully
2023-04-02T08:25:09,820 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20230402082402334-shutdown.cfg validated successfully
2023-04-02T08:25:11,615 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T08:25:11,615 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T08:25:11,616 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T08:25:11,616 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T08:25:11,617 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T08:25:11,617 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T08:25:11,618 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T08:25:11,618 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T08:25:11,619 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T08:25:11,619 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T08:25:11,639 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T08:25:11,639 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T08:25:11,647 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T08:25:11,647 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T08:25:11,759 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T08:25:11,759 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T08:25:11,760 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T08:25:11,760 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T08:25:11,762 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T08:25:11,762 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T08:25:11,763 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T08:25:11,763 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T08:25:11,765 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T08:25:11,765 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T08:25:12,183 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-02T08:25:12,183 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-02T08:25:12,916 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-02T08:25:12,920 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Successfully loaded /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-04-02T08:25:12,920 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - [PID]6453
2023-04-02T08:25:12,921 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Torch worker started.
2023-04-02T08:25:12,922 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T08:25:12,922 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T08:25:12,922 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Python runtime: 3.8.16
2023-04-02T08:25:12,932 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T08:25:12,932 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T08:25:12,946 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-02T08:25:12,951 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680398712951
2023-04-02T08:25:12,951 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680398712951
2023-04-02T08:25:12,994 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - model_name: VehicleDetection, batchSize: 40
2023-04-02T08:25:13,522 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 528
2023-04-02T08:25:13,522 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 528
2023-04-02T08:25:13,524 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T08:25:13,524 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T08:25:13,524 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - W-9000-VehicleDetection_1.0.ms:1891|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398713
2023-04-02T08:25:13,525 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:46|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398713
2023-04-02T08:25:13,837 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:33.3|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398713
2023-04-02T08:25:13,838 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:214.23638916015625|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398713
2023-04-02T08:25:13,838 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:23.93047332763672|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398713
2023-04-02T08:25:13,839 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:10.0|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398713
2023-04-02T08:25:13,840 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398713
2023-04-02T08:25:13,840 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398713
2023-04-02T08:25:13,841 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398713
2023-04-02T08:25:13,842 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:11169.05078125|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398713
2023-04-02T08:25:13,842 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1211.9140625|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398713
2023-04-02T08:25:13,843 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:11.8|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398713
2023-04-02T08:25:41,125 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680398741125
2023-04-02T08:25:41,125 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680398741125
2023-04-02T08:25:41,128 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Backend received inference at: 1680398741
2023-04-02T08:25:41,145 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Invoking custom service failed.
2023-04-02T08:25:41,146 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18
2023-04-02T08:25:41,146 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-02T08:25:41,146 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18
2023-04-02T08:25:41,146 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/service.py", line 120, in predict
2023-04-02T08:25:41,147 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2023-04-02T08:25:41,148 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 330, in handle
2023-04-02T08:25:41,148 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2023-04-02T08:25:41,149 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/tmp/models/8dbab09127504bdb9bafc4dd9717c81b/myhandler.py", line 47, in preprocess
2023-04-02T08:25:41,149 [INFO ] W-9000-VehicleDetection_1.0 ACCESS_LOG - /127.0.0.1:60370 "POST /predictions/VehicleDetection HTTP/1.1" 503 534
2023-04-02T08:25:41,150 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     im = letterbox(img, 640, stride=32, auto=True)[0]
2023-04-02T08:25:41,150 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398740
2023-04-02T08:25:41,150 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/tmp/models/8dbab09127504bdb9bafc4dd9717c81b/process.py", line 225, in letterbox
2023-04-02T08:25:41,151 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500332800, Inference time ns: 525913300
2023-04-02T08:25:41,151 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500332800, Inference time ns: 525913300
2023-04-02T08:25:41,151 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)
2023-04-02T08:25:41,153 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:10|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398741
2023-04-02T08:25:41,153 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - NameError: name 'cv2' is not defined
2023-04-02T08:26:13,774 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398773
2023-04-02T08:26:13,774 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:214.2363395690918|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398773
2023-04-02T08:26:13,775 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:23.930522918701172|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398773
2023-04-02T08:26:13,776 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:10.0|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398773
2023-04-02T08:26:13,776 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398773
2023-04-02T08:26:13,777 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398773
2023-04-02T08:26:13,778 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398773
2023-04-02T08:26:13,778 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:11138.8359375|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398773
2023-04-02T08:26:13,779 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1242.8671875|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398773
2023-04-02T08:26:13,779 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:12.0|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398773
2023-04-02T08:26:29,189 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T08:26:29,189 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T08:26:30,318 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T08:26:30,318 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T08:26:30,538 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: logs/config/20230402082625948-shutdown.cfg
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T08:26:30,538 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: logs/config/20230402082625948-shutdown.cfg
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T08:26:30,555 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20230402082625948-shutdown.cfg",
  "modelCount": 1,
  "created": 1680398785948,
  "models": {
    "VehicleDetection": {
      "1.0": {
        "defaultVersion": true,
        "marName": "VehicleDetection.mar",
        "minWorkers": 1,
        "maxWorkers": 8,
        "batchSize": 40,
        "maxBatchDelay": 500,
        "responseTimeout": 50
      }
    }
  }
}
2023-04-02T08:26:30,555 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20230402082625948-shutdown.cfg",
  "modelCount": 1,
  "created": 1680398785948,
  "models": {
    "VehicleDetection": {
      "1.0": {
        "defaultVersion": true,
        "marName": "VehicleDetection.mar",
        "minWorkers": 1,
        "maxWorkers": 8,
        "batchSize": 40,
        "maxBatchDelay": 500,
        "responseTimeout": 50
      }
    }
  }
}
2023-04-02T08:26:30,564 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20230402082625948-shutdown.cfg
2023-04-02T08:26:30,564 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20230402082625948-shutdown.cfg
2023-04-02T08:26:30,569 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20230402082625948-shutdown.cfg validated successfully
2023-04-02T08:26:30,569 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20230402082625948-shutdown.cfg validated successfully
2023-04-02T08:26:32,270 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T08:26:32,270 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T08:26:32,271 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T08:26:32,271 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T08:26:32,271 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T08:26:32,271 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T08:26:32,272 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T08:26:32,272 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T08:26:32,273 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T08:26:32,273 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T08:26:32,291 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T08:26:32,291 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T08:26:32,295 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T08:26:32,295 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T08:26:32,395 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T08:26:32,395 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T08:26:32,396 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T08:26:32,396 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T08:26:32,398 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T08:26:32,398 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T08:26:32,398 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T08:26:32,398 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T08:26:32,400 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T08:26:32,400 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T08:26:32,807 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-02T08:26:32,812 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Successfully loaded /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-04-02T08:26:32,813 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - [PID]6613
2023-04-02T08:26:32,815 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Torch worker started.
2023-04-02T08:26:32,816 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T08:26:32,816 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Python runtime: 3.8.16
2023-04-02T08:26:32,816 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T08:26:32,827 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T08:26:32,827 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T08:26:32,843 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-02T08:26:32,847 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680398792847
2023-04-02T08:26:32,847 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680398792847
2023-04-02T08:26:32,884 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - model_name: VehicleDetection, batchSize: 40
2023-04-02T08:26:33,259 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 374
2023-04-02T08:26:33,259 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 374
2023-04-02T08:26:33,260 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T08:26:33,260 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T08:26:33,261 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - W-9000-VehicleDetection_1.0.ms:977|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398793
2023-04-02T08:26:33,262 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:41|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398793
2023-04-02T08:26:34,015 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:66.7|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398794
2023-04-02T08:26:34,017 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:214.23638153076172|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398794
2023-04-02T08:26:34,018 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:23.93048095703125|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398794
2023-04-02T08:26:34,018 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:10.0|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398794
2023-04-02T08:26:34,019 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398794
2023-04-02T08:26:34,020 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398794
2023-04-02T08:26:34,021 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398794
2023-04-02T08:26:34,022 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:11146.125|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398794
2023-04-02T08:26:34,022 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1235.35546875|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398794
2023-04-02T08:26:34,023 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:11.9|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398794
2023-04-02T08:27:27,693 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680398847693
2023-04-02T08:27:27,693 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680398847693
2023-04-02T08:27:27,696 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Backend received inference at: 1680398847
2023-04-02T08:27:27,711 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15
2023-04-02T08:27:27,710 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Invoking custom service failed.
2023-04-02T08:27:27,711 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15
2023-04-02T08:27:27,712 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-02T08:27:27,712 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/service.py", line 120, in predict
2023-04-02T08:27:27,713 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2023-04-02T08:27:27,714 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 330, in handle
2023-04-02T08:27:27,715 [INFO ] W-9000-VehicleDetection_1.0 ACCESS_LOG - /127.0.0.1:60372 "POST /predictions/VehicleDetection HTTP/1.1" 503 535
2023-04-02T08:27:27,715 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2023-04-02T08:27:27,716 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398847
2023-04-02T08:27:27,716 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/tmp/models/3a4ae986b56d4afaaa744ee919743dae/myhandler.py", line 47, in preprocess
2023-04-02T08:27:27,717 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500390300, Inference time ns: 523883200
2023-04-02T08:27:27,717 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500390300, Inference time ns: 523883200
2023-04-02T08:27:27,717 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     im = letterbox(img, 640, stride=32, auto=True)[0]
2023-04-02T08:27:27,718 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:10|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398847
2023-04-02T08:27:27,718 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/tmp/models/3a4ae986b56d4afaaa744ee919743dae/process.py", line 225, in letterbox
2023-04-02T08:27:27,719 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)
2023-04-02T08:27:27,720 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - NameError: name 'cv2' is not defined
2023-04-02T08:27:34,492 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398854
2023-04-02T08:27:34,493 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:214.2363395690918|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398854
2023-04-02T08:27:34,494 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:23.930522918701172|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398854
2023-04-02T08:27:34,494 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:10.0|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398854
2023-04-02T08:27:34,495 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398854
2023-04-02T08:27:34,496 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398854
2023-04-02T08:27:34,496 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680398854
2023-04-02T08:27:34,497 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:11115.484375|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398854
2023-04-02T08:27:34,498 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1265.6796875|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398854
2023-04-02T08:27:34,499 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:12.2|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680398854
