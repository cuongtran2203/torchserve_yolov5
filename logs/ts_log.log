2023-04-02T17:41:31,114 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T17:41:31,114 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T17:41:32,233 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T17:41:32,233 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T17:41:32,487 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T17:41:32,487 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T17:41:32,506 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: VehicleDetection.mar
2023-04-02T17:41:32,506 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: VehicleDetection.mar
2023-04-02T17:41:34,326 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T17:41:34,326 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T17:41:34,327 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:41:34,327 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:41:34,328 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T17:41:34,328 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T17:41:34,329 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T17:41:34,329 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T17:41:34,346 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T17:41:34,346 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T17:41:34,349 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T17:41:34,349 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T17:41:34,465 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T17:41:34,465 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T17:41:34,466 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T17:41:34,466 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T17:41:34,467 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T17:41:34,467 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T17:41:34,468 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T17:41:34,468 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T17:41:34,470 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T17:41:34,470 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T17:41:34,862 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-02T17:41:34,862 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-02T17:41:35,560 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-02T17:41:35,564 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Successfully loaded /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-04-02T17:41:35,565 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - [PID]734
2023-04-02T17:41:35,565 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Torch worker started.
2023-04-02T17:41:35,566 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T17:41:35,566 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Python runtime: 3.8.16
2023-04-02T17:41:35,566 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T17:41:35,577 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T17:41:35,577 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T17:41:35,594 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-02T17:41:35,598 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432095598
2023-04-02T17:41:35,598 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432095598
2023-04-02T17:41:35,641 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - model_name: VehicleDetection, batchSize: 40
2023-04-02T17:41:35,941 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432095
2023-04-02T17:41:35,942 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:214.22923278808594|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432095
2023-04-02T17:41:35,948 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:23.93762969970703|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432095
2023-04-02T17:41:35,954 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:10.1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432095
2023-04-02T17:41:35,955 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432095
2023-04-02T17:41:35,956 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432095
2023-04-02T17:41:35,957 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432095
2023-04-02T17:41:35,958 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:10956.29296875|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432095
2023-04-02T17:41:35,959 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1419.1484375|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432095
2023-04-02T17:41:35,960 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:13.4|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432095
2023-04-02T17:41:36,271 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 629
2023-04-02T17:41:36,271 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 629
2023-04-02T17:41:36,272 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T17:41:36,272 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T17:41:36,273 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - W-9000-VehicleDetection_1.0.ms:1933|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432096
2023-04-02T17:41:36,274 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:47|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432096
2023-04-02T17:41:46,552 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432106552
2023-04-02T17:41:46,552 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432106552
2023-04-02T17:41:46,555 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Backend received inference at: 1680432106
2023-04-02T17:41:46,576 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Invoking custom service failed.
2023-04-02T17:41:46,577 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22
2023-04-02T17:41:46,578 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-02T17:41:46,577 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 22
2023-04-02T17:41:46,578 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/service.py", line 120, in predict
2023-04-02T17:41:46,579 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2023-04-02T17:41:46,580 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 330, in handle
2023-04-02T17:41:46,581 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2023-04-02T17:41:46,582 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/tmp/models/bcec7a487045499aa1510d99b1ae9670/myhandler.py", line 47, in preprocess
2023-04-02T17:41:46,582 [INFO ] W-9000-VehicleDetection_1.0 ACCESS_LOG - /127.0.0.1:35212 "POST /predictions/VehicleDetection HTTP/1.1" 503 543
2023-04-02T17:41:46,582 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     im = letterbox(img, 640, stride=32, auto=True)[0]
2023-04-02T17:41:46,583 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432106
2023-04-02T17:41:46,583 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/tmp/models/bcec7a487045499aa1510d99b1ae9670/process.py", line 225, in letterbox
2023-04-02T17:41:46,584 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500583300, Inference time ns: 532588800
2023-04-02T17:41:46,584 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500583300, Inference time ns: 532588800
2023-04-02T17:41:46,584 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)
2023-04-02T17:41:46,585 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:11|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432106
2023-04-02T17:41:46,585 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - NameError: name 'cv2' is not defined
2023-04-02T17:42:17,059 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T17:42:17,059 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T17:42:18,209 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T17:42:18,209 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T17:42:18,422 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: logs/config/20230402174208499-shutdown.cfg
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T17:42:18,422 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: logs/config/20230402174208499-shutdown.cfg
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T17:42:18,439 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20230402174208499-shutdown.cfg",
  "modelCount": 1,
  "created": 1680432128499,
  "models": {
    "VehicleDetection": {
      "1.0": {
        "defaultVersion": true,
        "marName": "VehicleDetection.mar",
        "minWorkers": 1,
        "maxWorkers": 8,
        "batchSize": 40,
        "maxBatchDelay": 500,
        "responseTimeout": 50
      }
    }
  }
}
2023-04-02T17:42:18,439 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20230402174208499-shutdown.cfg",
  "modelCount": 1,
  "created": 1680432128499,
  "models": {
    "VehicleDetection": {
      "1.0": {
        "defaultVersion": true,
        "marName": "VehicleDetection.mar",
        "minWorkers": 1,
        "maxWorkers": 8,
        "batchSize": 40,
        "maxBatchDelay": 500,
        "responseTimeout": 50
      }
    }
  }
}
2023-04-02T17:42:18,450 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20230402174208499-shutdown.cfg
2023-04-02T17:42:18,450 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20230402174208499-shutdown.cfg
2023-04-02T17:42:18,454 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20230402174208499-shutdown.cfg validated successfully
2023-04-02T17:42:18,454 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20230402174208499-shutdown.cfg validated successfully
2023-04-02T17:42:20,078 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T17:42:20,078 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T17:42:20,079 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:42:20,079 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:42:20,080 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:42:20,080 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:42:20,081 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T17:42:20,081 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T17:42:20,082 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T17:42:20,082 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T17:42:20,099 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T17:42:20,099 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T17:42:20,106 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T17:42:20,106 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T17:42:20,215 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T17:42:20,215 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T17:42:20,216 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T17:42:20,216 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T17:42:20,218 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T17:42:20,218 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T17:42:20,222 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T17:42:20,222 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T17:42:20,224 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T17:42:20,224 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T17:42:20,567 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-02T17:42:20,571 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Successfully loaded /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-04-02T17:42:20,572 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - [PID]881
2023-04-02T17:42:20,572 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Torch worker started.
2023-04-02T17:42:20,573 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T17:42:20,573 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Python runtime: 3.8.16
2023-04-02T17:42:20,573 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T17:42:20,585 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T17:42:20,585 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T17:42:20,601 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-02T17:42:20,606 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432140606
2023-04-02T17:42:20,606 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432140606
2023-04-02T17:42:20,643 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - model_name: VehicleDetection, batchSize: 40
2023-04-02T17:42:20,990 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 346
2023-04-02T17:42:20,990 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 346
2023-04-02T17:42:20,992 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T17:42:20,992 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T17:42:20,993 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - W-9000-VehicleDetection_1.0.ms:900|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432140
2023-04-02T17:42:20,994 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:42|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432140
2023-04-02T17:42:21,752 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432141
2023-04-02T17:42:21,754 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:214.2292251586914|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432141
2023-04-02T17:42:21,755 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:23.937637329101562|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432141
2023-04-02T17:42:21,756 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:10.1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432141
2023-04-02T17:42:21,757 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432141
2023-04-02T17:42:21,758 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432141
2023-04-02T17:42:21,759 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432141
2023-04-02T17:42:21,760 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:10938.55859375|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432141
2023-04-02T17:42:21,761 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1436.875|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432141
2023-04-02T17:42:21,762 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:13.6|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432141
2023-04-02T17:42:33,491 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432153491
2023-04-02T17:42:33,491 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432153491
2023-04-02T17:42:33,494 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Backend received inference at: 1680432153
2023-04-02T17:42:33,507 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Invoking custom service failed.
2023-04-02T17:42:33,508 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14
2023-04-02T17:42:33,508 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14
2023-04-02T17:42:33,508 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-02T17:42:33,510 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/service.py", line 120, in predict
2023-04-02T17:42:33,511 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2023-04-02T17:42:33,512 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 330, in handle
2023-04-02T17:42:33,512 [INFO ] W-9000-VehicleDetection_1.0 ACCESS_LOG - /127.0.0.1:35214 "POST /predictions/VehicleDetection HTTP/1.1" 503 533
2023-04-02T17:42:33,513 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2023-04-02T17:42:33,513 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432152
2023-04-02T17:42:33,514 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/tmp/models/6a10e7a1abd94be98d146a5235a52d17/myhandler.py", line 47, in preprocess
2023-04-02T17:42:33,514 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500578400, Inference time ns: 524097300
2023-04-02T17:42:33,514 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     im = letterbox(img, 640, stride=32, auto=True)[0]
2023-04-02T17:42:33,514 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500578400, Inference time ns: 524097300
2023-04-02T17:42:33,515 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/tmp/models/6a10e7a1abd94be98d146a5235a52d17/process.py", line 226, in letterbox
2023-04-02T17:42:33,516 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:11|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432153
2023-04-02T17:42:33,517 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)
2023-04-02T17:42:33,517 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - AttributeError: module 'cv2' has no attribute 'resize'
2023-04-02T17:43:47,874 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T17:43:47,874 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T17:43:49,010 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T17:43:49,010 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T17:43:49,220 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: logs/config/20230402174301916-shutdown.cfg
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T17:43:49,220 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: logs/config/20230402174301916-shutdown.cfg
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T17:43:49,239 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20230402174301916-shutdown.cfg",
  "modelCount": 1,
  "created": 1680432181916,
  "models": {
    "VehicleDetection": {
      "1.0": {
        "defaultVersion": true,
        "marName": "VehicleDetection.mar",
        "minWorkers": 1,
        "maxWorkers": 8,
        "batchSize": 40,
        "maxBatchDelay": 500,
        "responseTimeout": 50
      }
    }
  }
}
2023-04-02T17:43:49,239 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20230402174301916-shutdown.cfg",
  "modelCount": 1,
  "created": 1680432181916,
  "models": {
    "VehicleDetection": {
      "1.0": {
        "defaultVersion": true,
        "marName": "VehicleDetection.mar",
        "minWorkers": 1,
        "maxWorkers": 8,
        "batchSize": 40,
        "maxBatchDelay": 500,
        "responseTimeout": 50
      }
    }
  }
}
2023-04-02T17:43:49,251 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20230402174301916-shutdown.cfg
2023-04-02T17:43:49,251 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20230402174301916-shutdown.cfg
2023-04-02T17:43:49,256 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20230402174301916-shutdown.cfg validated successfully
2023-04-02T17:43:49,256 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20230402174301916-shutdown.cfg validated successfully
2023-04-02T17:43:50,915 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T17:43:50,915 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T17:43:50,916 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:43:50,916 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:43:50,917 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:43:50,917 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:43:50,918 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T17:43:50,918 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T17:43:50,919 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T17:43:50,919 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T17:43:50,937 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T17:43:50,937 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T17:43:50,942 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T17:43:50,942 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T17:43:51,057 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T17:43:51,057 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T17:43:51,058 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T17:43:51,058 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T17:43:51,059 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T17:43:51,059 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T17:43:51,060 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T17:43:51,060 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T17:43:51,062 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T17:43:51,062 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T17:43:51,437 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-02T17:43:51,440 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Successfully loaded /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-04-02T17:43:51,442 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - [PID]1049
2023-04-02T17:43:51,443 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Torch worker started.
2023-04-02T17:43:51,444 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T17:43:51,443 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Python runtime: 3.8.16
2023-04-02T17:43:51,444 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T17:43:51,456 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T17:43:51,456 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T17:43:51,472 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-02T17:43:51,477 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432231477
2023-04-02T17:43:51,477 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432231477
2023-04-02T17:43:51,517 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - model_name: VehicleDetection, batchSize: 40
2023-04-02T17:43:51,902 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 384
2023-04-02T17:43:51,902 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 384
2023-04-02T17:43:51,903 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T17:43:51,903 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T17:43:51,904 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - W-9000-VehicleDetection_1.0.ms:975|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432231
2023-04-02T17:43:51,905 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:44|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432231
2023-04-02T17:43:52,847 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:66.7|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432232
2023-04-02T17:43:52,848 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:214.09371185302734|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432232
2023-04-02T17:43:52,849 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:24.073150634765625|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432232
2023-04-02T17:43:52,850 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:10.1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432232
2023-04-02T17:43:52,850 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432232
2023-04-02T17:43:52,851 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432232
2023-04-02T17:43:52,852 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432232
2023-04-02T17:43:52,852 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:10933.08984375|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432232
2023-04-02T17:43:52,853 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1441.234375|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432232
2023-04-02T17:43:52,854 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:13.6|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432232
2023-04-02T17:44:05,135 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432245135
2023-04-02T17:44:05,135 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432245135
2023-04-02T17:44:05,139 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Backend received inference at: 1680432245
2023-04-02T17:44:05,216 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Invoking custom service failed.
2023-04-02T17:44:05,217 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 78
2023-04-02T17:44:05,217 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 78
2023-04-02T17:44:05,217 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-02T17:44:05,218 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/service.py", line 120, in predict
2023-04-02T17:44:05,218 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2023-04-02T17:44:05,219 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 334, in handle
2023-04-02T17:44:05,220 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     output = self.postprocess(output)
2023-04-02T17:44:05,220 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/tmp/models/6d3e313c16124843bab26a4b007a52c7/myhandler.py", line 64, in postprocess
2023-04-02T17:44:05,220 [INFO ] W-9000-VehicleDetection_1.0 ACCESS_LOG - /127.0.0.1:35218 "POST /predictions/VehicleDetection HTTP/1.1" 503 598
2023-04-02T17:44:05,221 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     y = non_max_suppression(preds, 0.25, 0.45)[0]
2023-04-02T17:44:05,221 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432244
2023-04-02T17:44:05,222 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/tmp/models/6d3e313c16124843bab26a4b007a52c7/process.py", line 140, in non_max_suppression
2023-04-02T17:44:05,222 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500413900, Inference time ns: 587088300
2023-04-02T17:44:05,222 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     t = time.time()
2023-04-02T17:44:05,222 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500413900, Inference time ns: 587088300
2023-04-02T17:44:05,223 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - NameError: name 'time' is not defined
2023-04-02T17:44:05,223 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:10|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432245
2023-04-02T17:44:45,901 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T17:44:45,901 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T17:44:47,026 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T17:44:47,026 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T17:44:47,247 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: logs/config/20230402174438489-shutdown.cfg
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T17:44:47,247 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: logs/config/20230402174438489-shutdown.cfg
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T17:44:47,262 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20230402174438489-shutdown.cfg",
  "modelCount": 1,
  "created": 1680432278489,
  "models": {
    "VehicleDetection": {
      "1.0": {
        "defaultVersion": true,
        "marName": "VehicleDetection.mar",
        "minWorkers": 1,
        "maxWorkers": 8,
        "batchSize": 40,
        "maxBatchDelay": 500,
        "responseTimeout": 50
      }
    }
  }
}
2023-04-02T17:44:47,262 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20230402174438489-shutdown.cfg",
  "modelCount": 1,
  "created": 1680432278489,
  "models": {
    "VehicleDetection": {
      "1.0": {
        "defaultVersion": true,
        "marName": "VehicleDetection.mar",
        "minWorkers": 1,
        "maxWorkers": 8,
        "batchSize": 40,
        "maxBatchDelay": 500,
        "responseTimeout": 50
      }
    }
  }
}
2023-04-02T17:44:47,273 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20230402174438489-shutdown.cfg
2023-04-02T17:44:47,273 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20230402174438489-shutdown.cfg
2023-04-02T17:44:47,277 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20230402174438489-shutdown.cfg validated successfully
2023-04-02T17:44:47,277 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20230402174438489-shutdown.cfg validated successfully
2023-04-02T17:44:48,958 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T17:44:48,958 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T17:44:48,960 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:44:48,960 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:44:48,961 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:44:48,961 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:44:48,961 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T17:44:48,961 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T17:44:48,962 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T17:44:48,962 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T17:44:48,983 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T17:44:48,983 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T17:44:48,988 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T17:44:48,988 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T17:44:49,111 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T17:44:49,111 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T17:44:49,112 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T17:44:49,112 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T17:44:49,115 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T17:44:49,115 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T17:44:49,116 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T17:44:49,116 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T17:44:49,118 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T17:44:49,118 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T17:44:49,491 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-02T17:44:49,495 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Successfully loaded /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-04-02T17:44:49,496 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - [PID]1215
2023-04-02T17:44:49,498 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Torch worker started.
2023-04-02T17:44:49,500 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T17:44:49,500 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T17:44:49,500 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Python runtime: 3.8.16
2023-04-02T17:44:49,511 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T17:44:49,511 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T17:44:49,529 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-02T17:44:49,537 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432289537
2023-04-02T17:44:49,537 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432289537
2023-04-02T17:44:49,577 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - model_name: VehicleDetection, batchSize: 40
2023-04-02T17:44:50,011 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 434
2023-04-02T17:44:50,011 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 434
2023-04-02T17:44:50,013 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T17:44:50,013 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T17:44:50,014 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - W-9000-VehicleDetection_1.0.ms:1038|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432290
2023-04-02T17:44:50,016 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:45|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432290
2023-04-02T17:44:50,823 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:66.7|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432290
2023-04-02T17:44:50,825 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:214.09371185302734|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432290
2023-04-02T17:44:50,825 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:24.073150634765625|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432290
2023-04-02T17:44:50,826 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:10.1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432290
2023-04-02T17:44:50,827 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432290
2023-04-02T17:44:50,828 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432290
2023-04-02T17:44:50,829 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432290
2023-04-02T17:44:50,830 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:10925.77734375|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432290
2023-04-02T17:44:50,830 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1448.75390625|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432290
2023-04-02T17:44:50,831 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:13.7|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432290
2023-04-02T17:44:56,865 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432296865
2023-04-02T17:44:56,865 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432296865
2023-04-02T17:44:56,869 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Backend received inference at: 1680432296
2023-04-02T17:44:56,935 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 66
2023-04-02T17:44:56,935 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Invoking custom service failed.
2023-04-02T17:44:56,935 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 66
2023-04-02T17:44:56,936 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-02T17:44:56,937 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/service.py", line 120, in predict
2023-04-02T17:44:56,938 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2023-04-02T17:44:56,938 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/torch_handler/base_handler.py", line 334, in handle
2023-04-02T17:44:56,939 [INFO ] W-9000-VehicleDetection_1.0 ACCESS_LOG - /127.0.0.1:35220 "POST /predictions/VehicleDetection HTTP/1.1" 503 586
2023-04-02T17:44:56,939 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     output = self.postprocess(output)
2023-04-02T17:44:56,939 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432296
2023-04-02T17:44:56,940 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/tmp/models/60e61583de6d40d08bca416871c3c04f/myhandler.py", line 64, in postprocess
2023-04-02T17:44:56,941 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500401500, Inference time ns: 575440300
2023-04-02T17:44:56,941 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500401500, Inference time ns: 575440300
2023-04-02T17:44:56,941 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     y = non_max_suppression(preds, 0.25, 0.45)[0]
2023-04-02T17:44:56,941 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:10|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432296
2023-04-02T17:44:56,942 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/tmp/models/60e61583de6d40d08bca416871c3c04f/process.py", line 187, in non_max_suppression
2023-04-02T17:44:56,943 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS
2023-04-02T17:44:56,944 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - NameError: name 'torchvision' is not defined
2023-04-02T17:45:22,141 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T17:45:22,141 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T17:45:23,282 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T17:45:23,282 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T17:45:23,492 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: logs/config/20230402174516535-shutdown.cfg
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T17:45:23,492 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: logs/config/20230402174516535-shutdown.cfg
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T17:45:23,508 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20230402174516535-shutdown.cfg",
  "modelCount": 1,
  "created": 1680432316535,
  "models": {
    "VehicleDetection": {
      "1.0": {
        "defaultVersion": true,
        "marName": "VehicleDetection.mar",
        "minWorkers": 1,
        "maxWorkers": 8,
        "batchSize": 40,
        "maxBatchDelay": 500,
        "responseTimeout": 50
      }
    }
  }
}
2023-04-02T17:45:23,508 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20230402174516535-shutdown.cfg",
  "modelCount": 1,
  "created": 1680432316535,
  "models": {
    "VehicleDetection": {
      "1.0": {
        "defaultVersion": true,
        "marName": "VehicleDetection.mar",
        "minWorkers": 1,
        "maxWorkers": 8,
        "batchSize": 40,
        "maxBatchDelay": 500,
        "responseTimeout": 50
      }
    }
  }
}
2023-04-02T17:45:23,517 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20230402174516535-shutdown.cfg
2023-04-02T17:45:23,517 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20230402174516535-shutdown.cfg
2023-04-02T17:45:23,521 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20230402174516535-shutdown.cfg validated successfully
2023-04-02T17:45:23,521 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20230402174516535-shutdown.cfg validated successfully
2023-04-02T17:45:25,204 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T17:45:25,204 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T17:45:25,205 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:45:25,205 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:45:25,206 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:45:25,206 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:45:25,207 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T17:45:25,207 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T17:45:25,208 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T17:45:25,208 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T17:45:25,224 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T17:45:25,224 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T17:45:25,228 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T17:45:25,228 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T17:45:25,339 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T17:45:25,339 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T17:45:25,340 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T17:45:25,340 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T17:45:25,342 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T17:45:25,342 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T17:45:25,343 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T17:45:25,343 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T17:45:25,345 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T17:45:25,345 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T17:45:25,686 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-02T17:45:25,690 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Successfully loaded /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-04-02T17:45:25,692 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - [PID]1380
2023-04-02T17:45:25,692 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Torch worker started.
2023-04-02T17:45:25,693 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T17:45:25,693 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T17:45:25,693 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Python runtime: 3.8.16
2023-04-02T17:45:25,703 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T17:45:25,703 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T17:45:25,721 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-02T17:45:25,726 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432325726
2023-04-02T17:45:25,726 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432325726
2023-04-02T17:45:25,763 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - model_name: VehicleDetection, batchSize: 40
2023-04-02T17:45:26,136 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 351
2023-04-02T17:45:26,136 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 351
2023-04-02T17:45:26,137 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T17:45:26,137 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T17:45:26,137 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - W-9000-VehicleDetection_1.0.ms:919|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432326
2023-04-02T17:45:26,138 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:61|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432326
2023-04-02T17:45:26,942 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432326
2023-04-02T17:45:26,944 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:214.09371185302734|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432326
2023-04-02T17:45:26,949 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:24.073150634765625|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432326
2023-04-02T17:45:26,950 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:10.1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432326
2023-04-02T17:45:26,951 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432326
2023-04-02T17:45:26,952 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432326
2023-04-02T17:45:26,953 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432326
2023-04-02T17:45:26,954 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:10923.92578125|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432326
2023-04-02T17:45:26,954 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1450.625|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432326
2023-04-02T17:45:26,955 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:13.7|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432326
2023-04-02T17:45:30,970 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432330970
2023-04-02T17:45:30,970 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432330970
2023-04-02T17:45:30,973 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Backend received inference at: 1680432330
2023-04-02T17:45:31,021 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:47.09|#ModelName:VehicleDetection,Level:Model|#hostname:DESKTOP-F1I07BF,requestID:fee368a4-cb96-48dd-a186-dd07731aa99b,timestamp:1680432331
2023-04-02T17:45:31,022 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:47.26|#ModelName:VehicleDetection,Level:Model|#hostname:DESKTOP-F1I07BF,requestID:fee368a4-cb96-48dd-a186-dd07731aa99b,timestamp:1680432331
2023-04-02T17:45:31,022 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Unable to serialize model output.
2023-04-02T17:45:31,023 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 50
2023-04-02T17:45:31,023 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 50
2023-04-02T17:45:31,023 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-02T17:45:31,024 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/protocol/otf_message_handler.py", line 128, in create_predict_response
2023-04-02T17:45:31,024 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     json_value = json.dumps(val, indent=2).encode("utf-8")
2023-04-02T17:45:31,025 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/json/__init__.py", line 234, in dumps
2023-04-02T17:45:31,026 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     return cls(
2023-04-02T17:45:31,026 [INFO ] W-9000-VehicleDetection_1.0 ACCESS_LOG - /127.0.0.1:35222 "POST /predictions/VehicleDetection HTTP/1.1" 503 568
2023-04-02T17:45:31,027 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/json/encoder.py", line 201, in encode
2023-04-02T17:45:31,027 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432330
2023-04-02T17:45:31,027 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     chunks = list(chunks)
2023-04-02T17:45:31,028 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500599500, Inference time ns: 558758700
2023-04-02T17:45:31,028 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500599500, Inference time ns: 558758700
2023-04-02T17:45:31,028 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/json/encoder.py", line 429, in _iterencode
2023-04-02T17:45:31,029 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432331
2023-04-02T17:45:31,029 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     yield from _iterencode_list(o, _current_indent_level)
2023-04-02T17:45:31,030 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/json/encoder.py", line 325, in _iterencode_list
2023-04-02T17:45:31,031 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     yield from chunks
2023-04-02T17:45:31,032 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/json/encoder.py", line 405, in _iterencode_dict
2023-04-02T17:45:31,033 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     yield from chunks
2023-04-02T17:45:31,033 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/json/encoder.py", line 438, in _iterencode
2023-04-02T17:45:31,034 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     o = _default(o)
2023-04-02T17:45:31,034 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/json/encoder.py", line 179, in default
2023-04-02T17:45:31,035 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     raise TypeError(f'Object of type {o.__class__.__name__} '
2023-04-02T17:45:31,036 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - TypeError: Object of type ndarray is not JSON serializable
2023-04-02T17:46:27,444 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432387
2023-04-02T17:46:27,444 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:214.09366989135742|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432387
2023-04-02T17:46:27,445 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:24.073192596435547|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432387
2023-04-02T17:46:27,446 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:10.1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432387
2023-04-02T17:46:27,447 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432387
2023-04-02T17:46:27,448 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432387
2023-04-02T17:46:27,449 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432387
2023-04-02T17:46:27,450 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:10863.8984375|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432387
2023-04-02T17:46:27,451 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1510.88671875|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432387
2023-04-02T17:46:27,452 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:14.2|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432387
2023-04-02T17:46:38,688 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T17:46:38,688 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T17:46:39,854 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T17:46:39,854 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T17:46:40,088 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: logs/config/20230402174634320-shutdown.cfg
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T17:46:40,088 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: logs/config/20230402174634320-shutdown.cfg
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T17:46:40,103 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20230402174634320-shutdown.cfg",
  "modelCount": 1,
  "created": 1680432394320,
  "models": {
    "VehicleDetection": {
      "1.0": {
        "defaultVersion": true,
        "marName": "VehicleDetection.mar",
        "minWorkers": 1,
        "maxWorkers": 8,
        "batchSize": 40,
        "maxBatchDelay": 500,
        "responseTimeout": 50
      }
    }
  }
}
2023-04-02T17:46:40,103 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20230402174634320-shutdown.cfg",
  "modelCount": 1,
  "created": 1680432394320,
  "models": {
    "VehicleDetection": {
      "1.0": {
        "defaultVersion": true,
        "marName": "VehicleDetection.mar",
        "minWorkers": 1,
        "maxWorkers": 8,
        "batchSize": 40,
        "maxBatchDelay": 500,
        "responseTimeout": 50
      }
    }
  }
}
2023-04-02T17:46:40,112 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20230402174634320-shutdown.cfg
2023-04-02T17:46:40,112 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20230402174634320-shutdown.cfg
2023-04-02T17:46:40,117 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20230402174634320-shutdown.cfg validated successfully
2023-04-02T17:46:40,117 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20230402174634320-shutdown.cfg validated successfully
2023-04-02T17:46:41,786 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T17:46:41,786 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T17:46:41,787 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:46:41,787 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:46:41,788 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:46:41,788 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:46:41,789 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T17:46:41,789 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T17:46:41,790 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T17:46:41,790 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T17:46:41,807 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T17:46:41,807 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T17:46:41,811 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T17:46:41,811 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T17:46:41,914 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T17:46:41,914 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T17:46:41,915 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T17:46:41,915 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T17:46:41,917 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T17:46:41,917 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T17:46:41,918 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T17:46:41,918 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T17:46:41,919 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T17:46:41,919 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T17:46:42,283 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-02T17:46:42,287 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Successfully loaded /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-04-02T17:46:42,289 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - [PID]1557
2023-04-02T17:46:42,290 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Torch worker started.
2023-04-02T17:46:42,291 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T17:46:42,291 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T17:46:42,291 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Python runtime: 3.8.16
2023-04-02T17:46:42,299 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T17:46:42,299 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T17:46:42,312 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-02T17:46:42,317 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432402317
2023-04-02T17:46:42,317 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432402317
2023-04-02T17:46:42,356 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - model_name: VehicleDetection, batchSize: 40
2023-04-02T17:46:42,742 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 386
2023-04-02T17:46:42,742 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 386
2023-04-02T17:46:42,743 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T17:46:42,743 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T17:46:42,743 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - W-9000-VehicleDetection_1.0.ms:943|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432402
2023-04-02T17:46:42,744 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:41|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432402
2023-04-02T17:46:43,489 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432403
2023-04-02T17:46:43,491 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:214.09371185302734|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432403
2023-04-02T17:46:43,492 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:24.073150634765625|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432403
2023-04-02T17:46:43,493 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:10.1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432403
2023-04-02T17:46:43,493 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432403
2023-04-02T17:46:43,494 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432403
2023-04-02T17:46:43,495 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432403
2023-04-02T17:46:43,495 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:10930.78515625|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432403
2023-04-02T17:46:43,496 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1443.734375|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432403
2023-04-02T17:46:43,497 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:13.6|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432403
2023-04-02T17:46:46,467 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432406467
2023-04-02T17:46:46,467 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432406467
2023-04-02T17:46:46,471 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Backend received inference at: 1680432406
2023-04-02T17:46:46,517 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:46.18|#ModelName:VehicleDetection,Level:Model|#hostname:DESKTOP-F1I07BF,requestID:f0beeec7-561d-460a-8d76-db07fc60ad55,timestamp:1680432406
2023-04-02T17:46:46,518 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 48
2023-04-02T17:46:46,518 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 48
2023-04-02T17:46:46,518 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:46.4|#ModelName:VehicleDetection,Level:Model|#hostname:DESKTOP-F1I07BF,requestID:f0beeec7-561d-460a-8d76-db07fc60ad55,timestamp:1680432406
2023-04-02T17:46:46,520 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Unable to serialize model output.
2023-04-02T17:46:46,520 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-02T17:46:46,521 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/protocol/otf_message_handler.py", line 128, in create_predict_response
2023-04-02T17:46:46,521 [INFO ] W-9000-VehicleDetection_1.0 ACCESS_LOG - /127.0.0.1:35224 "POST /predictions/VehicleDetection HTTP/1.1" 503 565
2023-04-02T17:46:46,522 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     json_value = json.dumps(val, indent=2).encode("utf-8")
2023-04-02T17:46:46,522 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432405
2023-04-02T17:46:46,522 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/json/__init__.py", line 234, in dumps
2023-04-02T17:46:46,523 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500566700, Inference time ns: 556304500
2023-04-02T17:46:46,523 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500566700, Inference time ns: 556304500
2023-04-02T17:46:46,523 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     return cls(
2023-04-02T17:46:46,524 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432406
2023-04-02T17:46:46,524 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/json/encoder.py", line 201, in encode
2023-04-02T17:46:46,526 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     chunks = list(chunks)
2023-04-02T17:46:46,527 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/json/encoder.py", line 429, in _iterencode
2023-04-02T17:46:46,527 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     yield from _iterencode_list(o, _current_indent_level)
2023-04-02T17:46:46,528 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/json/encoder.py", line 325, in _iterencode_list
2023-04-02T17:46:46,529 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     yield from chunks
2023-04-02T17:46:46,529 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/json/encoder.py", line 405, in _iterencode_dict
2023-04-02T17:46:46,530 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     yield from chunks
2023-04-02T17:46:46,531 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/json/encoder.py", line 325, in _iterencode_list
2023-04-02T17:46:46,531 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     yield from chunks
2023-04-02T17:46:46,532 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/json/encoder.py", line 438, in _iterencode
2023-04-02T17:46:46,533 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     o = _default(o)
2023-04-02T17:46:46,534 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -   File "/home/cuong/miniconda3/envs/project/lib/python3.8/json/encoder.py", line 179, in default
2023-04-02T17:46:46,535 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG -     raise TypeError(f'Object of type {o.__class__.__name__} '
2023-04-02T17:46:46,536 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - TypeError: Object of type float32 is not JSON serializable
2023-04-02T17:47:44,058 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432464
2023-04-02T17:47:44,059 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:214.09366989135742|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432464
2023-04-02T17:47:44,059 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:24.073192596435547|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432464
2023-04-02T17:47:44,060 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:10.1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432464
2023-04-02T17:47:44,061 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432464
2023-04-02T17:47:44,062 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432464
2023-04-02T17:47:44,062 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432464
2023-04-02T17:47:44,063 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:10862.52734375|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432464
2023-04-02T17:47:44,064 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1512.0|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432464
2023-04-02T17:47:44,064 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:14.2|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432464
2023-04-02T17:47:58,273 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T17:47:58,273 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-02T17:47:59,414 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T17:47:59,414 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-02T17:47:59,618 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: logs/config/20230402174751656-shutdown.cfg
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T17:47:59,618 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages
Current directory: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5
Temp directory: /tmp
Metrics config path: /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 12
Max heap size: 3166 M
Python executable: /home/cuong/miniconda3/envs/project/bin/python
Config file: logs/config/20230402174751656-shutdown.cfg
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Initial Models: VehicleDetection=VehicleDetection.mar
Log dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Metrics dir: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 26214400
Maximum Request Size: 26214400
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /mnt/c/Users/Tran Cuong/Documents/project/torchserve_yolov5/model-store
Model config: {"VehicleDetection": {"1.0": {"defaultVersion": true,"marName": "VehicleDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}},"LaneDetection": {"1.0": {"defaultVersion": true,"marName": "LaneDetection.mar","minWorkers": 1,"maxWorkers": 8,"batchSize": 40,"maxBatchDelay": 500,"responseTimeout": 50}}}
2023-04-02T17:47:59,635 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20230402174751656-shutdown.cfg",
  "modelCount": 1,
  "created": 1680432471656,
  "models": {
    "VehicleDetection": {
      "1.0": {
        "defaultVersion": true,
        "marName": "VehicleDetection.mar",
        "minWorkers": 1,
        "maxWorkers": 8,
        "batchSize": 40,
        "maxBatchDelay": 500,
        "responseTimeout": 50
      }
    }
  }
}
2023-04-02T17:47:59,635 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20230402174751656-shutdown.cfg",
  "modelCount": 1,
  "created": 1680432471656,
  "models": {
    "VehicleDetection": {
      "1.0": {
        "defaultVersion": true,
        "marName": "VehicleDetection.mar",
        "minWorkers": 1,
        "maxWorkers": 8,
        "batchSize": 40,
        "maxBatchDelay": 500,
        "responseTimeout": 50
      }
    }
  }
}
2023-04-02T17:47:59,645 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20230402174751656-shutdown.cfg
2023-04-02T17:47:59,645 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20230402174751656-shutdown.cfg
2023-04-02T17:47:59,649 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20230402174751656-shutdown.cfg validated successfully
2023-04-02T17:47:59,649 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20230402174751656-shutdown.cfg validated successfully
2023-04-02T17:48:01,312 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T17:48:01,312 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model VehicleDetection
2023-04-02T17:48:01,313 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:48:01,313 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:48:01,313 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:48:01,313 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model VehicleDetection
2023-04-02T17:48:01,314 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T17:48:01,314 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model VehicleDetection loaded.
2023-04-02T17:48:01,315 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T17:48:01,315 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: VehicleDetection, count: 1
2023-04-02T17:48:01,333 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T17:48:01,333 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/cuong/miniconda3/envs/project/bin/python, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2023-04-02T17:48:01,337 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T17:48:01,337 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-02T17:48:01,454 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T17:48:01,454 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2023-04-02T17:48:01,455 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T17:48:01,455 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-02T17:48:01,457 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T17:48:01,457 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2023-04-02T17:48:01,458 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T17:48:01,458 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-02T17:48:01,460 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T17:48:01,460 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2023-04-02T17:48:01,788 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-02T17:48:01,792 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Successfully loaded /home/cuong/miniconda3/envs/project/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2023-04-02T17:48:01,793 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - [PID]1749
2023-04-02T17:48:01,794 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Torch worker started.
2023-04-02T17:48:01,794 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T17:48:01,794 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change null -> WORKER_STARTED
2023-04-02T17:48:01,794 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Python runtime: 3.8.16
2023-04-02T17:48:01,807 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T17:48:01,807 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-02T17:48:01,822 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-02T17:48:01,827 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432481827
2023-04-02T17:48:01,827 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432481827
2023-04-02T17:48:01,863 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - model_name: VehicleDetection, batchSize: 40
2023-04-02T17:48:02,235 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 372
2023-04-02T17:48:02,235 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 372
2023-04-02T17:48:02,237 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T17:48:02,237 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-VehicleDetection_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-02T17:48:02,237 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - W-9000-VehicleDetection_1.0.ms:911|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432482
2023-04-02T17:48:02,238 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:39|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432482
2023-04-02T17:48:03,033 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432483
2023-04-02T17:48:03,035 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:214.09371185302734|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432483
2023-04-02T17:48:03,036 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:24.073150634765625|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432483
2023-04-02T17:48:03,036 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:10.1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432483
2023-04-02T17:48:03,037 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:0.0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432483
2023-04-02T17:48:03,038 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432483
2023-04-02T17:48:03,039 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-F1I07BF,timestamp:1680432483
2023-04-02T17:48:03,039 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:10926.51953125|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432483
2023-04-02T17:48:03,040 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:1448.04296875|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432483
2023-04-02T17:48:03,041 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:13.7|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432483
2023-04-02T17:48:05,326 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432485326
2023-04-02T17:48:05,326 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1680432485326
2023-04-02T17:48:05,330 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_LOG - Backend received inference at: 1680432485
2023-04-02T17:48:05,375 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:45.29|#ModelName:VehicleDetection,Level:Model|#hostname:DESKTOP-F1I07BF,requestID:64fef3c7-6dd5-4623-bdca-454cef4523b6,timestamp:1680432485
2023-04-02T17:48:05,376 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 47
2023-04-02T17:48:05,376 [INFO ] W-9000-VehicleDetection_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:45.46|#ModelName:VehicleDetection,Level:Model|#hostname:DESKTOP-F1I07BF,requestID:64fef3c7-6dd5-4623-bdca-454cef4523b6,timestamp:1680432485
2023-04-02T17:48:05,376 [INFO ] W-9000-VehicleDetection_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 47
2023-04-02T17:48:05,378 [INFO ] W-9000-VehicleDetection_1.0 ACCESS_LOG - /127.0.0.1:35226 "POST /predictions/VehicleDetection HTTP/1.1" 200 564
2023-04-02T17:48:05,379 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432484
2023-04-02T17:48:05,380 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500474400, Backend time ns: 53886300
2023-04-02T17:48:05,380 [DEBUG] W-9000-VehicleDetection_1.0 org.pytorch.serve.job.Job - Waiting time ns: 500474400, Backend time ns: 53886300
2023-04-02T17:48:05,381 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - QueueTime.ms:500|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432485
2023-04-02T17:48:05,381 [INFO ] W-9000-VehicleDetection_1.0 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:DESKTOP-F1I07BF,timestamp:1680432485
